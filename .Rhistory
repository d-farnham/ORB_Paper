########################################
rm(list = ls())
source("R/GetSeasonDate.R")
load("Processed_Data/Shifted_reanalysis/RIP_EWD_M_O_all.RData")
# try the stan model
source("R/stan_logistic_mod_no_lag.R")
dat_include = RIP_EWD_M_O_all %>% dplyr::group_by(model) %>%
dplyr::mutate(west_index_anom = west_index_anom,
east_index_anom = east_index_anom,
M_index_anom = M_index_anom,
NPH_index_anom = NPH_index_anom) %>%
dplyr::select(date, model, RIP, M_index_anom, O_index_anom, west_index_anom, east_index_anom, NPH_index_anom, RIP_lag1) %>%
dplyr::filter(!is.na(west_index_anom) &
!is.na(east_index_anom) &
!is.na(M_index_anom) &
!is.na(NPH_index_anom) &
!is.na(RIP_lag1))
training_data = dat_include %>% dplyr::filter(model == "obs") %>% dplyr::ungroup()
testing_data1 = dat_include %>% dplyr::filter(model == 1) %>% dplyr::ungroup()
testing_data4 = dat_include %>% dplyr::filter(model == 4) %>% dplyr::ungroup()
# set parameters for the MCMC
iter = 1000
thin = 2
chains = 4
# for(llag in c(TRUE,FALSE)){
# # want to to the lag model or the non-lag model?
#
# if(!llag){
dat_list_1 = list(T_train = nrow(training_data),
T_test = nrow(testing_data1),
P = 5,
X_train = as.matrix(training_data %>% dplyr::select(west_index_anom, east_index_anom, NPH_index_anom, M_index_anom, O_index_anom)),
X_test = as.matrix(testing_data1 %>% dplyr::select(west_index_anom, east_index_anom, NPH_index_anom, M_index_anom, O_index_anom)),
y_train = training_data$RIP)
stan_fit_1 =
stan(model_code = stan_logistic_mod_no_lag,
data = dat_list_1,
verbose = FALSE,
seed = 22,
chains = chains,
iter = iter,
thin = thin)
print(stan_fit_1, pars = c("alpha","beta"))
plot(stan_fit_1, pars = c("alpha","beta"))
traceplot(stan_fit_1, pars = c("alpha","beta"))
dat_list_4 = list(T_train = nrow(training_data),
T_test = nrow(testing_data4),
P = 5,
X_train = as.matrix(training_data %>% dplyr::select(west_index_anom, east_index_anom, NPH_index_anom, M_index_anom, O_index_anom)),
X_test = as.matrix(testing_data4 %>% dplyr::select(west_index_anom, east_index_anom, NPH_index_anom, M_index_anom, O_index_anom)),
y_train = training_data$RIP)
stan_fit_4 =
stan(model_code = stan_logistic_mod_no_lag,
data = dat_list_4,
verbose = FALSE,
seed = 22,
chains = chains,
iter = iter,
thin = thin)
print(stan_fit_4, pars = c("alpha","beta"))
plot(stan_fit_4, pars = c("alpha","beta"))
traceplot(stan_fit_4, pars = c("alpha","beta"))
# look at the testing sim
RIP_test4_sim = data.frame(date = testing_data4$date,
RIP = testing_data4$RIP,
model = 4,
t(data.frame(rstan::extract(stan_fit_4, pars = "y_test_sim"))))
RIP_test1_sim = data.frame(date = testing_data1$date,
RIP = testing_data1$RIP,
model = 1,
t(data.frame(rstan::extract(stan_fit_1, pars = "y_test_sim"))))
RIP_test_sim = rbind(RIP_test1_sim, RIP_test4_sim)
RIP_test_sim_yearly0 = melt(RIP_test_sim, id.vars = c("date","model","RIP")) %>% dplyr::group_by(year = lubridate::year(date), variable, model) %>%
dplyr::summarise(RIP_sim = sum(value),
RIP = sum(RIP))
### TESTING ###
smoothing_window = 10
RIP_sim_yearly = RIP_test_sim_yearly0
RIP_sim_yearly$RIP_smooth = RIP_sim_yearly$RIP_sim_smooth = NA
for(mmodel in c(1,4)){
for(vvar in unique(RIP_sim_yearly$variable)){
RIP_sim_yearly$RIP_smooth[RIP_sim_yearly$variable == vvar &
RIP_sim_yearly$model == mmodel] = ksmooth(RIP_sim_yearly$year[RIP_sim_yearly$variable == vvar &
RIP_sim_yearly$model == mmodel],
RIP_sim_yearly$RIP[RIP_sim_yearly$variable == vvar &
RIP_sim_yearly$model == mmodel],
kernel = "normal",
bandwidth = smoothing_window,
n.points = length(RIP_sim_yearly$RIP[RIP_sim_yearly$variable == vvar &
RIP_sim_yearly$model == mmodel]))$y
RIP_sim_yearly$RIP_sim_smooth[RIP_sim_yearly$variable == vvar &
RIP_sim_yearly$model == mmodel] = ksmooth(RIP_sim_yearly$year[RIP_sim_yearly$variable == vvar &
RIP_sim_yearly$model == mmodel],
RIP_sim_yearly$RIP_sim[RIP_sim_yearly$variable == vvar &
RIP_sim_yearly$model == mmodel],
kernel = "normal",
bandwidth = smoothing_window,
n.points = length(RIP_sim_yearly$RIP_sim[RIP_sim_yearly$variable == vvar &
RIP_sim_yearly$model == mmodel]))$y
print(vvar)
}
}
RIP_sim_yearly_training = RIP_sim_yearly %>%
dplyr::group_by(year,model) %>%
dplyr::summarise(RIPs_smooth_mean = mean(RIP_sim_smooth, na.rm = TRUE),
RIPs_smooth_25 = quantile(RIP_sim_smooth, probs = 0.25, na.rm = TRUE),
RIPs_smooth_75 = quantile(RIP_sim_smooth, probs = 0.75, na.rm = TRUE),
RIPs_smooth_2.5 = quantile(RIP_sim_smooth, probs = 0.025, na.rm = TRUE),
RIPs_smooth_97.5 = quantile(RIP_sim_smooth, probs = 0.975, na.rm = TRUE),
RIP_smooth = median(RIP_smooth, na.rm = TRUE))
RIP_sim_yearly_training_plot =  RIP_sim_yearly_training %>% dplyr::filter(year > (1950 + (smoothing_window/2 - 1)) &
year < (2005 - (smoothing_window/2 - 1)))
line.width = 1
RIP_mod_obs_compare_1 =
ggplot(RIP_sim_yearly_training_plot) +
geom_ribbon(aes(x = year, ymin = RIPs_smooth_25, ymax = RIPs_smooth_75, group = model), alpha = 0.5) +
geom_ribbon(aes(x = year, ymin = RIPs_smooth_2.5, ymax = RIPs_smooth_97.5, group = model), alpha = 0.5) +
geom_line(aes(year, RIPs_smooth_mean, group = model), linetype = "dashed", size = line.width) +
geom_line(aes(year, RIP_smooth, group = model), size = line.width) +
theme_bw() +
annotate("text", label = "a)", x = 1956.5, y = 2.9, size = 6, colour = "black") +
scale_y_continuous(limits = c(0,3)) +
ylab("# REP")
### TESTING ###
# source("R/ma.R")
# s_window = 10
# RIP_test_sim_yearly = RIP_test_sim_yearly0 %>% dplyr::group_by(variable, model) %>%
#   dplyr::mutate(RIP_sim_smooth = ma(RIP_sim, n = s_window),
#                 RIP_smooth = ma(RIP, n = s_window)) %>%
#   dplyr::group_by(year, model) %>%
#   dplyr::summarise(RIPs_smooth_mean = mean(RIP_sim_smooth, na.rm = TRUE),
#                    RIPs_smooth_25 = quantile(RIP_sim_smooth, probs = 0.25, na.rm = TRUE),
#                    RIPs_smooth_75 = quantile(RIP_sim_smooth, probs = 0.75, na.rm = TRUE),
#                    RIPs_smooth_2.5 = quantile(RIP_sim_smooth, probs = 0.025, na.rm = TRUE),
#                    RIPs_smooth_97.5 = quantile(RIP_sim_smooth, probs = 0.975, na.rm = TRUE),
#                    RIP_smooth = median(RIP_smooth, na.rm = TRUE))
#
# # the observed REP record
RIP_obs = dat_include %>% dplyr::filter(model == "obs") %>%
dplyr::group_by(year = lubridate::year(date)) %>%
dplyr::summarise(RIP = sum(RIP))
#
# line.width = 1
# RIP_mod_obs_compare_1 =
# ggplot(RIP_test_sim_yearly) +
#   geom_ribbon(aes(x = year, ymin = RIPs_smooth_25, ymax = RIPs_smooth_75, group = model), alpha = 0.5) +
#   geom_ribbon(aes(x = year, ymin = RIPs_smooth_2.5, ymax = RIPs_smooth_97.5, group = model), alpha = 0.5) +
#   geom_line(aes(year, RIPs_smooth_mean, group = model), linetype = "dashed", size = line.width) +
#   geom_line(aes(year, RIP_smooth, group = model), size = line.width) +
#   theme_bw() +
#   annotate("text", label = "a)", x = 1951.5, y = 2.9, size = 6, colour = "black") +
#   scale_y_continuous(limits = c(0,3)) +
#   ylab("# REP")
#
# need to normalize by:
iter*chains/2/thin
alpha.line = 1
col.line = "grey80"
bin_breaks = seq(-0.5,12.5,1)
bin_labels = as.character(bin_breaks-0.5)
hist_lims = data.frame(xlim = c(0.5,8.6),
ylim = c(0,40))
RIP_mod_obs_compare_2 =
ggplot() +
stat_bin(data = RIP_test_sim_yearly0[RIP_test_sim_yearly0$model == 1,],
aes(x = RIP_sim, y =..count../(1000), group = model),
geom = "step", linetype = "dashed", size = line.width,
breaks = bin_breaks) +
stat_bin(data = RIP_test_sim_yearly0[RIP_test_sim_yearly0$model == 4,],
aes(x = RIP_sim, y =..count../(1000), group = model),
geom = "step", linetype = "dashed", size = line.width,
breaks = bin_breaks) +
stat_bin(data = RIP_test_sim_yearly0[RIP_test_sim_yearly0$model == 1,],
aes(x = RIP, y =..count../(1000), group = model),
geom = "step", size = line.width,
breaks = bin_breaks) +
stat_bin(data = RIP_test_sim_yearly0[RIP_test_sim_yearly0$model == 4,],
aes(x = RIP, y =..count../(1000), group = model),
geom = "step", size = line.width,
breaks = bin_breaks) +
stat_bin(data = RIP_obs,
aes(x = RIP, y=..count..),
geom = "step", size = line.width,
breaks = bin_breaks, col = "red") +
annotate("text", label = "b)", x = 0.75, y = 38.5, size = 6, colour = "black") +
labs(x = "# REP",
y = "count") +
coord_cartesian(xlim = hist_lims$xlim,
ylim = hist_lims$ylim) +
scale_x_continuous(breaks = bin_breaks,
labels = bin_labels) +
theme_bw()
# now check the RIP lag 1 correlation by simulation
RIP_sim_daily = melt(RIP_test_sim, id.vars = c("date","model","RIP")) %>% dplyr::group_by(variable) %>%
dplyr::mutate(value_lag1 = lag(value, 1),
RIP_lag1 = lag(RIP, 1))
# create a three way contingency table for the simulations
RIP_sim_daily_table = as.data.frame(ftable(RIP_sim_daily %>% dplyr::select(value, value_lag1, variable, model)))
for(ii in 1:(nrow(RIP_sim_daily_table)/4)){
RIP_mod_persist0 = data.frame(variable = RIP_sim_daily_table$variable[ii*4],
set = paste0("ens # ",RIP_sim_daily_table$model[ii*4]),
lag1_persist_prob = RIP_sim_daily_table$Freq[ii*4] / (RIP_sim_daily_table$Freq[(ii-1)*4+2] + RIP_sim_daily_table$Freq[ii*4]),
lag1_persist_prob_norm = (RIP_sim_daily_table$Freq[ii*4] / (RIP_sim_daily_table$Freq[(ii-1)*4+2] + RIP_sim_daily_table$Freq[ii*4]))/
((RIP_sim_daily_table$Freq[(ii-1)*4+2] + RIP_sim_daily_table$Freq[ii*4])/sum(RIP_sim_daily_table$Freq[((ii-1)*4 + 1):((ii-1)*4 + 4)])))
if(ii == 1){RIP_mod_persist = RIP_mod_persist0}
if(ii > 1){RIP_mod_persist = rbind(RIP_mod_persist,RIP_mod_persist0)}
print(ii)
}
# create a thw way contingency table for the observations
RIP_obs_daily_table = as.data.frame(ftable(training_data %>% dplyr::select(RIP, RIP_lag1)))
RIP_obs_persist = data.frame(variable = "obs",
set = "obs",
lag1_persist_prob = RIP_obs_daily_table$Freq[4] / (RIP_obs_daily_table$Freq[2] + RIP_obs_daily_table$Freq[4]),
lag1_persist_prob_norm = (RIP_obs_daily_table$Freq[4] / (RIP_obs_daily_table$Freq[2] + RIP_obs_daily_table$Freq[4]))/
((RIP_obs_daily_table$Freq[2] + RIP_obs_daily_table$Freq[4])/sum(RIP_obs_daily_table$Freq)))
RIP_persist = rbind(RIP_mod_persist, RIP_obs_persist)
presist_prob_test =
ggplot(RIP_persist) +
geom_boxplot(aes(y = lag1_persist_prob_norm, x = set)) +
theme_bw() +
labs(y = expression(P(REP[t] ~"|" ~ REP[t-lag])/P(REP)),
x = "") +
annotate("text", label = "c)", x = 0.75, y = 24, size = 6, colour = "black") +
scale_y_continuous(limits = c(0,25))
pdf('Final figures/REVISED/Figure_8.pdf', width = 12, height = 2.75)
grid.arrange(RIP_mod_obs_compare_1,
RIP_mod_obs_compare_2,
presist_prob_test,
layout_matrix = rbind(c(1,1,1,2,2,2,3,3)))
dev.off()
rm(list = ls())
source("R/GetSeasonDate.R")
rm(list = ls())
source("R/GetSeasonDate.R")
load("Processed_Data/Shifted_reanalysis/REP_EWD_M_O_all.RData")
source("R/stan_logistic_mod_no_lag.R")
dat_include = REP_EWD_M_O_all %>% dplyr::group_by(model) %>%
dplyr::mutate(west_index_anom = west_index_anom,
east_index_anom = east_index_anom,
M_index_anom = M_index_anom,
NPH_index_anom = NPH_index_anom) %>%
dplyr::select(date, model, REP, M_index_anom, O_index_anom, west_index_anom, east_index_anom, NPH_index_anom, REP_lag1) %>%
dplyr::filter(!is.na(west_index_anom) &
!is.na(east_index_anom) &
!is.na(M_index_anom) &
!is.na(NPH_index_anom) &
!is.na(REP_lag1))
training_data = dat_include %>% dplyr::filter(model == "obs") %>% dplyr::ungroup()
testing_data1 = dat_include %>% dplyr::filter(model == 1) %>% dplyr::ungroup()
testing_data4 = dat_include %>% dplyr::filter(model == 4) %>% dplyr::ungroup()
iter = 1000
thin = 2
chains = 4
dat_list_1 = list(T_train = nrow(training_data),
T_test = nrow(testing_data1),
P = 5,
X_train = as.matrix(training_data %>% dplyr::select(west_index_anom, east_index_anom, NPH_index_anom, M_index_anom, O_index_anom)),
X_test = as.matrix(testing_data1 %>% dplyr::select(west_index_anom, east_index_anom, NPH_index_anom, M_index_anom, O_index_anom)),
y_train = training_data$REP)
iter*chains/2/thin
source('R/sim_historic_model.R') # make Fig 8
source('R/load_GCM_future.R')
source('R/make_GCM_indices_future.R')
source('R/combine_indices_future.R')
source('R/sim_future_model.R') # make Fig 9
source('R/sim_historic_future_model_sep_effects.R') # make Fig 10
source('R/sup_figs.R') # make Figs S1, S2, S3, S4, S6, S7
rm(list = ls())
source("R/GetSeasonDate.R")
load(file = 'Processed_Data/mod_REP.RData')
load(file = 'Processed_Data/CPC_mod_cell_REP.RData')
load(file = 'Processed_Data/mod_CPC_thresh_REP.RData')
MOD_REP = mod_REP %>% dplyr::filter(model %in% c(1,4)) %>% dplyr::mutate(model = ifelse(model == 4, "GCM ens 2",paste0("GCM ens ",model))) %>% data.frame()
OBS_REP = CPC_mod_cell_REP %>% dplyr::mutate(model = "OBS") %>% data.frame()
REP_MOD_OBS_counts = rbind(MOD_REP, OBS_REP) %>% dplyr::mutate(month = lubridate::month(date)) %>%
dplyr::group_by(model, month) %>%
dplyr::summarise(REPs = sum(REP, na.rm = TRUE)) %>% dplyr::group_by(model) %>%
dplyr::mutate(percent_REPs = REPs/sum(REPs))
pdf('Final figures/Figure_S2.pdf', height = 2, width = 8)
ggplot(REP_MOD_OBS_counts) +
geom_bar(aes(month, percent_REPs*100), stat = "identity") +
facet_wrap(~model) +
labs(x = "month", y = "% of REPs") +
scale_x_continuous(breaks = 1:12) +
theme_bw()
dev.off()
source('R/sup_figs.R') # make Figs S1, S2, S3, S4, S6, S7
source('R/sup_figs.R') # make Figs S1, S2, S3, S4, S6, S7
source('R/sup_figs.R') # make Figs S1, S2, S3, S4, S6, S7
rm(list = ls())
source('R/GetSeasonDate.R')
load(file = 'Processed_Data/Z_700_mod_field.RData')
Z_700_mod_field = Z_700_mod_field %>% dplyr::filter(model %in% c(1,4)) %>%
dplyr::mutate(season = GetSeasonDate(date)) %>%
dplyr::filter(season == 'MAM')
colnames(Z_700_mod_field)[5] = "z_700"
Z_700_mod_field = Z_700_mod_field %>% dplyr::mutate(model = ifelse(model == 4, "GCM ens 2", paste0("GCM ens ",model)))
season_mean_sd_mod = Z_700_mod_field %>% dplyr::group_by(lon,lat,model) %>%
dplyr::summarise(z_700_clim = mean(z_700),
z_700_sd = sd(z_700))
season_mean_sd_mod_long = melt(season_mean_sd_mod, id.vars = c('lon', 'lat', 'model'))
load('Processed_Data/Shifted_reanalysis/Z_700.RData')
Z_700 = Z_700 %>% dplyr::mutate(season = GetSeasonDate(date)) %>%
dplyr::filter(season == 'MAM')
colnames(Z_700)[5] = "z_700"
season_mean_sd_obs = Z_700 %>% dplyr::group_by(lon,lat) %>%
dplyr::summarise(z_700_clim = mean(z_700),
z_700_sd = sd(z_700))
season_mean_sd_obs$model = "NCEP/NCAR"
season_mean_sd_all = rbind(season_mean_sd_mod, season_mean_sd_obs)
new_lat = seq(16, 60, by = 4)
new_lon = seq(208, 312, by = 4)
season_mean_sd_all_interp = list()
for(mm in 1:length(unique(season_mean_sd_all$model))){
mmodel = 	unique(season_mean_sd_all$model)[mm]
season_mean_sd_all_interp[[mm]] = data.frame(model = mmodel,
lat = rep(new_lat, each = length(new_lon)),
lon = rep(new_lon, length(new_lat)),
z_700_sd = c(interp(x = season_mean_sd_all[season_mean_sd_all$model == mmodel,]$lon,
y = season_mean_sd_all[season_mean_sd_all$model == mmodel,]$lat,
z = season_mean_sd_all[season_mean_sd_all$model == mmodel,]$z_700_sd,
xo = new_lon,
yo = new_lat)$z))
}
summary(season_mean_sd_all)
summary(Z_700)
season_mean_sd_obs = Z_700 %>% dplyr::group_by(lon,lat) %>%
dplyr::summarise(z_700_clim = mean(z_700),
z_700_sd = sd(z_700))
head(season_mean_sd_obs)
warnings()
summary(season_mean_sd_obs)
head(Z_700)
rm(list = ls())
source('R/GetSeasonDate.R')
load(file = 'Processed_Data/Z_700_mod_field.RData')
Z_700_mod_field = Z_700_mod_field %>% dplyr::filter(model %in% c(1,4)) %>%
dplyr::mutate(season = GetSeasonDate(date)) %>%
dplyr::filter(season == 'MAM')
head(Z_700_mod_field)
colnames(Z_700_mod_field)[5] = "z_700"
Z_700_mod_field = Z_700_mod_field %>% dplyr::mutate(model = ifelse(model == 4, "GCM ens 2", paste0("GCM ens ",model)))
head(Z_700_mod_field)
load('Processed_Data/Shifted_reanalysis/Z_700.RData')
Z_700 = Z_700 %>% dplyr::mutate(season = GetSeasonDate(date)) %>%
dplyr::filter(season == 'MAM')
head(Z_700)
Z_700 = Z_700 %>% dplyr::mutate(season = GetSeasonDate(date)) %>%
dplyr::filter(season == 'MAM')
colnames(Z_700)[4] = "z_700"
season_mean_sd_obs = Z_700 %>% dplyr::group_by(lon,lat) %>%
dplyr::summarise(z_700_clim = mean(z_700),
z_700_sd = sd(z_700))
season_mean_sd_obs$model = "NCEP/NCAR"
season_mean_sd_all = rbind(season_mean_sd_mod, season_mean_sd_obs)
rm(list = ls())
source('R/GetSeasonDate.R')
load(file = 'Processed_Data/Z_700_mod_field.RData')
Z_700_mod_field = Z_700_mod_field %>% dplyr::filter(model %in% c(1,4)) %>%
dplyr::mutate(season = GetSeasonDate(date)) %>%
dplyr::filter(season == 'MAM')
colnames(Z_700_mod_field)[5] = "z_700"
Z_700_mod_field = Z_700_mod_field %>% dplyr::mutate(model = ifelse(model == 4, "GCM ens 2", paste0("GCM ens ",model)))
season_mean_sd_mod = Z_700_mod_field %>% dplyr::group_by(lon,lat,model) %>%
dplyr::summarise(z_700_clim = mean(z_700),
z_700_sd = sd(z_700))
season_mean_sd_mod_long = melt(season_mean_sd_mod, id.vars = c('lon', 'lat', 'model'))
# now load the reanalysis data
load('Processed_Data/Shifted_reanalysis/Z_700.RData')
Z_700 = Z_700 %>% dplyr::mutate(season = GetSeasonDate(date)) %>%
dplyr::filter(season == 'MAM')
colnames(Z_700)[4] = "z_700"
season_mean_sd_obs = Z_700 %>% dplyr::group_by(lon,lat) %>%
dplyr::summarise(z_700_clim = mean(z_700),
z_700_sd = sd(z_700))
season_mean_sd_obs$model = "NCEP/NCAR"
season_mean_sd_all = rbind(season_mean_sd_mod, season_mean_sd_obs)
new_lat = seq(16, 60, by = 4)
new_lon = seq(208, 312, by = 4)
season_mean_sd_all_interp = list()
for(mm in 1:length(unique(season_mean_sd_all$model))){
mmodel = 	unique(season_mean_sd_all$model)[mm]
season_mean_sd_all_interp[[mm]] = data.frame(model = mmodel,
lat = rep(new_lat, each = length(new_lon)),
lon = rep(new_lon, length(new_lat)),
z_700_sd = c(interp(x = season_mean_sd_all[season_mean_sd_all$model == mmodel,]$lon,
y = season_mean_sd_all[season_mean_sd_all$model == mmodel,]$lat,
z = season_mean_sd_all[season_mean_sd_all$model == mmodel,]$z_700_sd,
xo = new_lon,
yo = new_lat)$z))
}
season_mean_sd_mod_interp = do.call("rbind", season_mean_sd_all_interp[unique(season_mean_sd_all$model) != "NCEP/NCAR"])
season_mean_sd_obs_interp = do.call("rbind", season_mean_sd_all_interp[unique(season_mean_sd_all$model) == "NCEP/NCAR"])
plot_data = merge(season_mean_sd_obs_interp,season_mean_sd_mod_interp, by = c("lon", "lat")) %>%
dplyr::mutate(z_700_sd = z_700_sd.y - z_700_sd.x,
model = paste0(model.y," - ", model.x))
world <- data.frame(map("world", plot=FALSE)[c("x","y")])
source("R/load_basin_boundary.R")
pdf("Final figures/Figure_S6.pdf", width=8, height=2.5) # NOTE: the original submission included the state boundaries
ggplot(data = plot_data) +
geom_tile(aes(x = (lon-360),y = lat,fill=(z_700_sd))) +
facet_wrap(~model, ncol = 3) +
scale_fill_gradient2(name=expression(paste(Delta, sigma[Z[700]], " (m)")),
limits = c(-22,22),
midpoint = 0,low="blue", mid = "white",  high = "red",na.value = "grey") +
geom_path(data=world, aes(x,y), size = 0.2, alpha = 0.6) +
scale_y_continuous(limits = c(15,60)) +
labs(x = "Longitude", y = "Latitude") +
scale_x_continuous(limits = c(-145,-45), breaks = c(-140, -100, -60))  +
theme_bw() +
coord_map("ortho", orientation=c(40, -95, 0)) +
geom_polygon(aes(x = long, y = lat, group = group), alpha = 0.5, data = basin_points)
dev.off()
source('R/sup_figs.R') # make Figs S1, S2, S3, S4, S6, S7
rm(list = ls())
source('R/GetSeasonDate.R')
load(file = 'Processed_Data/U_200_mod_MAM.RData')
rm(list = ls())
source('R/GetSeasonDate.R')
load(file = 'Processed_Data/data.file.path')
reanal_output = nc_open(paste0(data.file.path,'REANALYSIS_data/u_200_REANALYSIS.nc'))
time = ncvar_get(reanal_output, varid = "T", start = c(1), count = c(-1))
dates = data.frame(year = c(rep(1949:2016, each = 12),rep(2017,3)),
month = c(rep(1:12,(2016-1949+1)),1:3),
day = 1)
date = as.Date(paste(dates$year,
dates$month,
dates$day, sep = "-"),
origin = "1948-01-01 00:00:00")
lat = ncvar_get(reanal_output, varid = "Y", start = c(1), count = c(-1))
lon = ncvar_get(reanal_output, varid = "X", start = c(1), count = c(-1))
start_date = which(date > "1949-12-31" &
date < "2005-01-01")[1]
count_date = sum(date > "1949-12-31" &
date < "2005-01-01")
U_200 = melt(ncvar_get(reanal_output,
varid = "u",
start = c(1,1,1,start_date),
count = c(length(lon),length(lat),1,count_date)))
U_200 = U_200 %>% dplyr::mutate(lon = lon[Var1],
lat = lat[Var2],
date = date[which(date > "1949-12-31" &
date < "2005-01-01")][Var3],
season = GetSeasonDate(date),
u_200 = value) %>%
dplyr::select(c(date, season, lon, lat, u_200))
U_200_MAM = U_200 %>% dplyr::filter(season %in% c("MAM"))
save(U_200_MAM, file = 'Processed_Data/U_200_MAM.RData')
source('R/sup_figs.R') # make Figs S1, S2, S3, S4, S6, S7
akima
?akima
version
rm(list = ls())
package.list <- list("akima","dataRetrieval","data.table","dplyr","ggmap","ggplot2","gridExtra","rstan",
"Kendall","locfit", "lubridate","maps","ncdf4","readr","reshape2","tidyr","epitools")
source('R/load_packages.R') # clear workspace, clear console, load packages
source("R/GetSeasonDate.R")
source('R/plot_grids.R') # make Fig 1
# all codes run in RStudio version 1.0.136 and R version R version 3.3.3
# Older and newer versions of RStudio and R have not been tested
rm(list = ls())
package.list <- list("akima","dataRetrieval","data.table","dplyr","ggmap","ggplot2","gridExtra","rstan",
"Kendall","locfit", "lubridate","maps","ncdf4","readr","reshape2","tidyr","epitools")
source('R/load_packages.R') # clear workspace, clear console, load packages
source("R/GetSeasonDate.R")
time.noww = proc.time()
source('R/load_reanalysis.R') # this can take several minutes to run -- processed data is already stored
proc.time() - time.noww
rm(list = ls())
source('R/GetSeasonDate.R')
load(file = 'Processed_Data/data.file.path')
rm(list = ls())
source('R/GetSeasonDate.R')
load(file = 'Processed_Data/data.file.path')
reanal_output = nc_open(path = '/Users/davidfarnham/Google Drive/ORB_Paper/Raw_Data/REANALYSIS_data/u_200_REANALYSIS.nc')
reanal_output = nc_open(path = '/Users/davidfarnham/Google Drive/ORB_Paper/Raw_Data/REANALYSIS_data/u_200_REANALYSIS.nc')
reanal_output = nc_open(path = '/Users/davidfarnham/Google Drive/ORB_Paper/Raw_Data/REANALYSIS_data/u_200_REANALYSIS.nc')
rm(list = ls())
source('R/GetSeasonDate.R')
reanal_output = nc_open(path = '/Users/davidfarnham/Google Drive/ORB_Paper/Raw_Data/REANALYSIS_data/u_200_REANALYSIS.nc')
reanal_output = nc_open('/Users/davidfarnham/Google Drive/ORB_Paper/Raw_Data/REANALYSIS_data/u_200_REANALYSIS.nc')
rm(list = ls())
source('R/GetSeasonDate.R')
reanal_output = nc_open('/Users/davidfarnham/Google Drive/ORB_Paper/Raw_Data/REANALYSIS_data/u_200_REANALYSIS.nc')
time = ncvar_get(reanal_output, varid = "T", start = c(1), count = c(-1))
dates = data.frame(year = c(rep(1949:2016, each = 12),rep(2017,3)),
month = c(rep(1:12,(2016-1949+1)),1:3),
day = 1)
date = as.Date(paste(dates$year,
dates$month,
dates$day, sep = "-"),
origin = "1948-01-01 00:00:00")
lat = ncvar_get(reanal_output, varid = "Y", start = c(1), count = c(-1))
lon = ncvar_get(reanal_output, varid = "X", start = c(1), count = c(-1))
start_date = which(date > "1949-12-31" &
date < "2005-01-01")[1]
count_date = sum(date > "1949-12-31" &
date < "2005-01-01")
U_200 = melt(ncvar_get(reanal_output,
varid = "u",
start = c(1,1,1,start_date),
count = c(length(lon),length(lat),1,count_date)))
U_200 = U_200 %>% dplyr::mutate(lon = lon[Var1],
lat = lat[Var2],
date = date[which(date > "1949-12-31" &
date < "2005-01-01")][Var3],
season = GetSeasonDate(date),
u_200 = value) %>%
dplyr::select(c(date, season, lon, lat, u_200))
U_200_MAM = U_200 %>% dplyr::filter(season %in% c("MAM"))
save(U_200_MAM, file = 'Processed_Data/U_200_MAM.RData')
rm(list = ls())
